2023-05-07 16:01:33,510:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:01:33,512:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        4,280
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 6,784
Trainable params: 6,784
Non-trainable params: 0
===========================================================================
2023-05-07 16:02:49,767:INFO: -------------Data Proccessed------------
2023-05-07 16:02:49,808:INFO: -------------Teacher Model Loaded------------
2023-05-07 16:02:52,533:INFO: Epoch: 1 - loss: 0.2905467420 - test_loss: 0.6222797501
2023-05-07 16:02:52,535:INFO: -------- Save Best Model! --------
2023-05-07 16:02:54,828:INFO: Epoch: 2 - loss: 0.2385429191 - test_loss: 0.5355699426
2023-05-07 16:02:54,830:INFO: -------- Save Best Model! --------
2023-05-07 16:02:57,169:INFO: Epoch: 3 - loss: 0.1990942355 - test_loss: 0.4633648941
2023-05-07 16:02:57,170:INFO: -------- Save Best Model! --------
2023-05-07 16:02:59,544:INFO: Epoch: 4 - loss: 0.1654914727 - test_loss: 0.4021429907
2023-05-07 16:02:59,546:INFO: -------- Save Best Model! --------
2023-05-07 16:03:01,914:INFO: Epoch: 5 - loss: 0.1371887314 - test_loss: 0.3516448017
2023-05-07 16:03:01,916:INFO: -------- Save Best Model! --------
2023-05-07 16:03:04,234:INFO: Epoch: 6 - loss: 0.1139921367 - test_loss: 0.3111224923
2023-05-07 16:03:04,236:INFO: -------- Save Best Model! --------
2023-05-07 16:03:06,561:INFO: Epoch: 7 - loss: 0.0953920354 - test_loss: 0.2791788444
2023-05-07 16:03:06,563:INFO: -------- Save Best Model! --------
2023-05-07 16:03:08,873:INFO: Epoch: 8 - loss: 0.0806991929 - test_loss: 0.2544458210
2023-05-07 16:03:08,875:INFO: -------- Save Best Model! --------
2023-05-07 16:03:11,204:INFO: Epoch: 9 - loss: 0.0691921274 - test_loss: 0.2354693704
2023-05-07 16:03:11,206:INFO: -------- Save Best Model! --------
2023-05-07 16:03:13,520:INFO: Epoch: 10 - loss: 0.0602339952 - test_loss: 0.2209130776
2023-05-07 16:03:13,522:INFO: -------- Save Best Model! --------
2023-05-07 16:03:15,914:INFO: Epoch: 11 - loss: 0.0532144444 - test_loss: 0.2097287124
2023-05-07 16:03:15,915:INFO: -------- Save Best Model! --------
2023-05-07 16:03:18,243:INFO: Epoch: 12 - loss: 0.0476961618 - test_loss: 0.2012582087
2023-05-07 16:03:18,244:INFO: -------- Save Best Model! --------
2023-05-07 16:03:20,552:INFO: Epoch: 13 - loss: 0.0433103082 - test_loss: 0.1947348496
2023-05-07 16:03:20,554:INFO: -------- Save Best Model! --------
2023-05-07 16:03:22,853:INFO: Epoch: 14 - loss: 0.0397631454 - test_loss: 0.1896179362
2023-05-07 16:03:22,854:INFO: -------- Save Best Model! --------
2023-05-07 16:03:25,194:INFO: Epoch: 15 - loss: 0.0368133722 - test_loss: 0.1857154862
2023-05-07 16:03:25,195:INFO: -------- Save Best Model! --------
2023-05-07 16:03:27,521:INFO: Epoch: 16 - loss: 0.0342209445 - test_loss: 0.1832528214
2023-05-07 16:03:27,522:INFO: -------- Save Best Model! --------
2023-05-07 16:03:29,836:INFO: Epoch: 17 - loss: 0.0319104515 - test_loss: 0.1811682137
2023-05-07 16:03:29,838:INFO: -------- Save Best Model! --------
2023-05-07 16:03:32,171:INFO: Epoch: 18 - loss: 0.0297110309 - test_loss: 0.1794377158
2023-05-07 16:03:32,173:INFO: -------- Save Best Model! --------
2023-05-07 16:03:34,534:INFO: Epoch: 19 - loss: 0.0275985771 - test_loss: 0.1814107235
2023-05-07 16:03:34,534:INFO: Early Stop Left: 9
2023-05-07 16:03:36,965:INFO: Epoch: 20 - loss: 0.0254468645 - test_loss: 0.1778042413
2023-05-07 16:03:36,966:INFO: -------- Save Best Model! --------
2023-05-07 16:03:39,386:INFO: Epoch: 21 - loss: 0.0234143449 - test_loss: 0.1771203730
2023-05-07 16:03:39,387:INFO: -------- Save Best Model! --------
2023-05-07 16:03:41,784:INFO: Epoch: 22 - loss: 0.0215847677 - test_loss: 0.1760073195
2023-05-07 16:03:41,785:INFO: -------- Save Best Model! --------
2023-05-07 16:03:44,155:INFO: Epoch: 23 - loss: 0.0199790941 - test_loss: 0.1748415550
2023-05-07 16:03:44,156:INFO: -------- Save Best Model! --------
2023-05-07 16:03:46,548:INFO: Epoch: 24 - loss: 0.0184987524 - test_loss: 0.1725940021
2023-05-07 16:03:46,550:INFO: -------- Save Best Model! --------
2023-05-07 16:03:48,889:INFO: Epoch: 25 - loss: 0.0171653347 - test_loss: 0.1770423473
2023-05-07 16:03:48,889:INFO: Early Stop Left: 9
2023-05-07 16:03:51,226:INFO: Epoch: 26 - loss: 0.0162066901 - test_loss: 0.1743065809
2023-05-07 16:03:51,226:INFO: Early Stop Left: 8
2023-05-07 16:03:53,567:INFO: Epoch: 27 - loss: 0.0153083262 - test_loss: 0.1711725460
2023-05-07 16:03:53,568:INFO: -------- Save Best Model! --------
2023-05-07 16:03:55,972:INFO: Epoch: 28 - loss: 0.0144722626 - test_loss: 0.1724917638
2023-05-07 16:03:55,972:INFO: Early Stop Left: 9
2023-05-07 16:03:58,419:INFO: Epoch: 29 - loss: 0.0138647572 - test_loss: 0.1725913650
2023-05-07 16:03:58,419:INFO: Early Stop Left: 8
2023-05-07 16:04:00,812:INFO: Epoch: 30 - loss: 0.0132159623 - test_loss: 0.1719124110
2023-05-07 16:04:00,812:INFO: Early Stop Left: 7
2023-05-07 16:04:03,215:INFO: Epoch: 31 - loss: 0.0126687512 - test_loss: 0.1717279190
2023-05-07 16:04:03,215:INFO: Early Stop Left: 6
2023-05-07 16:04:05,645:INFO: Epoch: 32 - loss: 0.0120931775 - test_loss: 0.1695251256
2023-05-07 16:04:05,646:INFO: -------- Save Best Model! --------
2023-05-07 16:04:08,004:INFO: Epoch: 33 - loss: 0.0118548826 - test_loss: 0.1684197038
2023-05-07 16:04:08,005:INFO: -------- Save Best Model! --------
2023-05-07 16:04:10,367:INFO: Epoch: 34 - loss: 0.0112290043 - test_loss: 0.1705989374
2023-05-07 16:04:10,368:INFO: Early Stop Left: 9
2023-05-07 16:04:12,707:INFO: Epoch: 35 - loss: 0.0108439917 - test_loss: 0.1702689001
2023-05-07 16:04:12,707:INFO: Early Stop Left: 8
2023-05-07 16:04:15,046:INFO: Epoch: 36 - loss: 0.0104925353 - test_loss: 0.1698315623
2023-05-07 16:04:15,046:INFO: Early Stop Left: 7
2023-05-07 16:04:17,409:INFO: Epoch: 37 - loss: 0.0101633889 - test_loss: 0.1704735376
2023-05-07 16:04:17,409:INFO: Early Stop Left: 6
2023-05-07 16:04:19,749:INFO: Epoch: 38 - loss: 0.0098711811 - test_loss: 0.1702200669
2023-05-07 16:04:19,749:INFO: Early Stop Left: 5
2023-05-07 16:04:22,079:INFO: Epoch: 39 - loss: 0.0095759702 - test_loss: 0.1684196132
2023-05-07 16:04:22,081:INFO: -------- Save Best Model! --------
2023-05-07 16:04:24,414:INFO: Epoch: 40 - loss: 0.0092894371 - test_loss: 0.1695021275
2023-05-07 16:04:24,414:INFO: Early Stop Left: 9
2023-05-07 16:04:26,740:INFO: Epoch: 41 - loss: 0.0090101215 - test_loss: 0.1729483181
2023-05-07 16:04:26,740:INFO: Early Stop Left: 8
2023-05-07 16:04:29,146:INFO: Epoch: 42 - loss: 0.0088802122 - test_loss: 0.1715495728
2023-05-07 16:04:29,146:INFO: Early Stop Left: 7
2023-05-07 16:04:31,488:INFO: Epoch: 43 - loss: 0.0085748637 - test_loss: 0.1676518203
2023-05-07 16:04:31,490:INFO: -------- Save Best Model! --------
2023-05-07 16:04:33,850:INFO: Epoch: 44 - loss: 0.0083089121 - test_loss: 0.1657203877
2023-05-07 16:04:33,851:INFO: -------- Save Best Model! --------
2023-05-07 16:04:36,271:INFO: Epoch: 45 - loss: 0.0080955380 - test_loss: 0.1668555177
2023-05-07 16:04:36,271:INFO: Early Stop Left: 9
2023-05-07 16:04:38,671:INFO: Epoch: 46 - loss: 0.0079289451 - test_loss: 0.1696761549
2023-05-07 16:04:38,671:INFO: Early Stop Left: 8
2023-05-07 16:04:41,066:INFO: Epoch: 47 - loss: 0.0077128484 - test_loss: 0.1694332147
2023-05-07 16:04:41,066:INFO: Early Stop Left: 7
2023-05-07 16:04:43,445:INFO: Epoch: 48 - loss: 0.0074911487 - test_loss: 0.1660539766
2023-05-07 16:04:43,445:INFO: Early Stop Left: 6
2023-05-07 16:04:45,795:INFO: Epoch: 49 - loss: 0.0073447761 - test_loss: 0.1701416637
2023-05-07 16:04:45,795:INFO: Early Stop Left: 5
2023-05-07 16:04:48,122:INFO: Epoch: 50 - loss: 0.0070655799 - test_loss: 0.1645790388
2023-05-07 16:04:48,123:INFO: -------- Save Best Model! --------
2023-05-07 16:05:29,887:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:05:29,889:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        4,280
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 6,784
Trainable params: 6,784
Non-trainable params: 0
===========================================================================
2023-05-07 16:13:57,327:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:13:57,330:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        696
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 3,200
Trainable params: 3,200
Non-trainable params: 0
===========================================================================
2023-05-07 16:20:20,915:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:20:20,918:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
│    │    └─ModuleList: 3-2                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 10,096
Trainable params: 10,096
Non-trainable params: 0
===========================================================================
2023-05-07 16:21:35,032:INFO: -------------Data Proccessed------------
2023-05-07 16:21:35,102:INFO: -------------Teacher Model Loaded------------
2023-05-07 16:21:40,002:INFO: Epoch: 1 - loss: 0.2663883834 - test_loss: 0.5463495066
2023-05-07 16:21:40,005:INFO: -------- Save Best Model! --------
2023-05-07 16:21:44,547:INFO: Epoch: 2 - loss: 0.1913581488 - test_loss: 0.4221579709
2023-05-07 16:21:44,549:INFO: -------- Save Best Model! --------
2023-05-07 16:21:49,098:INFO: Epoch: 3 - loss: 0.1387538081 - test_loss: 0.3376870061
2023-05-07 16:21:49,100:INFO: -------- Save Best Model! --------
2023-05-07 16:21:53,646:INFO: Epoch: 4 - loss: 0.1028946513 - test_loss: 0.2811196995
2023-05-07 16:21:53,649:INFO: -------- Save Best Model! --------
2023-05-07 16:21:58,197:INFO: Epoch: 5 - loss: 0.0786042678 - test_loss: 0.2435955990
2023-05-07 16:21:58,199:INFO: -------- Save Best Model! --------
2023-05-07 16:22:02,751:INFO: Epoch: 6 - loss: 0.0622760493 - test_loss: 0.2191970403
2023-05-07 16:22:02,753:INFO: -------- Save Best Model! --------
2023-05-07 16:22:07,305:INFO: Epoch: 7 - loss: 0.0513464503 - test_loss: 0.2032502897
2023-05-07 16:22:07,307:INFO: -------- Save Best Model! --------
2023-05-07 16:22:11,849:INFO: Epoch: 8 - loss: 0.0440037382 - test_loss: 0.1930403273
2023-05-07 16:22:11,851:INFO: -------- Save Best Model! --------
2023-05-07 16:22:16,393:INFO: Epoch: 9 - loss: 0.0390048816 - test_loss: 0.1865377041
2023-05-07 16:22:16,395:INFO: -------- Save Best Model! --------
2023-05-07 16:22:20,953:INFO: Epoch: 10 - loss: 0.0355854640 - test_loss: 0.1821166310
2023-05-07 16:22:20,955:INFO: -------- Save Best Model! --------
2023-05-07 16:22:25,519:INFO: Epoch: 11 - loss: 0.0331579787 - test_loss: 0.1792888403
2023-05-07 16:22:25,522:INFO: -------- Save Best Model! --------
2023-05-07 16:22:30,082:INFO: Epoch: 12 - loss: 0.0314152603 - test_loss: 0.1774316704
2023-05-07 16:22:30,084:INFO: -------- Save Best Model! --------
2023-05-07 16:22:34,640:INFO: Epoch: 13 - loss: 0.0301229509 - test_loss: 0.1762440566
2023-05-07 16:22:34,642:INFO: -------- Save Best Model! --------
2023-05-07 16:22:39,195:INFO: Epoch: 14 - loss: 0.0289987211 - test_loss: 0.1747859062
2023-05-07 16:22:39,197:INFO: -------- Save Best Model! --------
2023-05-07 16:22:43,750:INFO: Epoch: 15 - loss: 0.0274482871 - test_loss: 0.1735962913
2023-05-07 16:22:43,752:INFO: -------- Save Best Model! --------
2023-05-07 16:22:48,311:INFO: Epoch: 16 - loss: 0.0254644725 - test_loss: 0.1733010987
2023-05-07 16:22:48,313:INFO: -------- Save Best Model! --------
2023-05-07 16:22:52,865:INFO: Epoch: 17 - loss: 0.0233822696 - test_loss: 0.1729735767
2023-05-07 16:22:52,867:INFO: -------- Save Best Model! --------
2023-05-07 16:22:57,428:INFO: Epoch: 18 - loss: 0.0212476257 - test_loss: 0.1728900402
2023-05-07 16:22:57,430:INFO: -------- Save Best Model! --------
2023-05-07 16:23:01,980:INFO: Epoch: 19 - loss: 0.0190659480 - test_loss: 0.1722366348
2023-05-07 16:23:01,982:INFO: -------- Save Best Model! --------
2023-05-07 16:23:06,548:INFO: Epoch: 20 - loss: 0.0173396068 - test_loss: 0.1796032674
2023-05-07 16:23:06,548:INFO: Early Stop Left: 9
2023-05-07 16:23:11,115:INFO: Epoch: 21 - loss: 0.0158420172 - test_loss: 0.1829371340
2023-05-07 16:23:11,115:INFO: Early Stop Left: 8
2023-05-07 16:23:15,666:INFO: Epoch: 22 - loss: 0.0148227705 - test_loss: 0.1759463131
2023-05-07 16:23:15,666:INFO: Early Stop Left: 7
2023-05-07 16:23:20,213:INFO: Epoch: 23 - loss: 0.0139506787 - test_loss: 0.1756081746
2023-05-07 16:23:20,213:INFO: Early Stop Left: 6
2023-05-07 16:23:24,758:INFO: Epoch: 24 - loss: 0.0132194751 - test_loss: 0.1698821134
2023-05-07 16:23:24,760:INFO: -------- Save Best Model! --------
2023-05-07 16:23:29,313:INFO: Epoch: 25 - loss: 0.0125071645 - test_loss: 0.1724421306
2023-05-07 16:23:29,313:INFO: Early Stop Left: 9
2023-05-07 16:23:33,883:INFO: Epoch: 26 - loss: 0.0117934265 - test_loss: 0.1745368059
2023-05-07 16:23:33,883:INFO: Early Stop Left: 8
2023-05-07 16:23:38,446:INFO: Epoch: 27 - loss: 0.0114728876 - test_loss: 0.1808718230
2023-05-07 16:23:38,446:INFO: Early Stop Left: 7
2023-05-07 16:23:43,014:INFO: Epoch: 28 - loss: 0.0108484131 - test_loss: 0.1719297514
2023-05-07 16:23:43,014:INFO: Early Stop Left: 6
2023-05-07 16:23:47,597:INFO: Epoch: 29 - loss: 0.0103790961 - test_loss: 0.1697127943
2023-05-07 16:23:47,598:INFO: -------- Save Best Model! --------
2023-05-07 16:23:52,162:INFO: Epoch: 30 - loss: 0.0099874101 - test_loss: 0.1735632512
2023-05-07 16:23:52,163:INFO: Early Stop Left: 9
2023-05-07 16:23:56,726:INFO: Epoch: 31 - loss: 0.0095694882 - test_loss: 0.1703087973
2023-05-07 16:23:56,726:INFO: Early Stop Left: 8
2023-05-07 16:24:01,314:INFO: Epoch: 32 - loss: 0.0091959015 - test_loss: 0.1653150015
2023-05-07 16:24:01,316:INFO: -------- Save Best Model! --------
2023-05-07 16:24:05,912:INFO: Epoch: 33 - loss: 0.0089608561 - test_loss: 0.1683705547
2023-05-07 16:24:05,913:INFO: Early Stop Left: 9
2023-05-07 16:24:10,498:INFO: Epoch: 34 - loss: 0.0086088271 - test_loss: 0.1714338700
2023-05-07 16:24:10,499:INFO: Early Stop Left: 8
2023-05-07 16:24:15,105:INFO: Epoch: 35 - loss: 0.0084471784 - test_loss: 0.1699361534
2023-05-07 16:24:15,105:INFO: Early Stop Left: 7
2023-05-07 16:24:19,685:INFO: Epoch: 36 - loss: 0.0082173748 - test_loss: 0.1734184270
2023-05-07 16:24:19,685:INFO: Early Stop Left: 6
2023-05-07 16:24:24,269:INFO: Epoch: 37 - loss: 0.0079381970 - test_loss: 0.1694226954
2023-05-07 16:24:24,269:INFO: Early Stop Left: 5
2023-05-07 16:24:28,872:INFO: Epoch: 38 - loss: 0.0078114082 - test_loss: 0.1699265009
2023-05-07 16:24:28,872:INFO: Early Stop Left: 4
2023-05-07 16:24:33,444:INFO: Epoch: 39 - loss: 0.0077106284 - test_loss: 0.1678854692
2023-05-07 16:24:33,444:INFO: Early Stop Left: 3
2023-05-07 16:24:38,033:INFO: Epoch: 40 - loss: 0.0076130887 - test_loss: 0.1707128722
2023-05-07 16:24:38,034:INFO: Early Stop Left: 2
2023-05-07 16:24:42,656:INFO: Epoch: 41 - loss: 0.0074062905 - test_loss: 0.1680392994
2023-05-07 16:24:42,656:INFO: Early Stop Left: 1
2023-05-07 16:24:47,266:INFO: Epoch: 42 - loss: 0.0072762732 - test_loss: 0.1650894450
2023-05-07 16:24:47,268:INFO: -------- Save Best Model! --------
2023-05-07 16:24:51,896:INFO: Epoch: 43 - loss: 0.0069964966 - test_loss: 0.1670668398
2023-05-07 16:24:51,896:INFO: Early Stop Left: 9
2023-05-07 16:24:56,501:INFO: Epoch: 44 - loss: 0.0068722494 - test_loss: 0.1635670440
2023-05-07 16:24:56,503:INFO: -------- Save Best Model! --------
2023-05-07 16:25:01,145:INFO: Epoch: 45 - loss: 0.0067407191 - test_loss: 0.1671936156
2023-05-07 16:25:01,146:INFO: Early Stop Left: 9
2023-05-07 16:25:05,735:INFO: Epoch: 46 - loss: 0.0066236227 - test_loss: 0.1661677648
2023-05-07 16:25:05,735:INFO: Early Stop Left: 8
2023-05-07 16:25:10,288:INFO: Epoch: 47 - loss: 0.0065120317 - test_loss: 0.1646148254
2023-05-07 16:25:10,289:INFO: Early Stop Left: 7
2023-05-07 16:25:14,832:INFO: Epoch: 48 - loss: 0.0064092986 - test_loss: 0.1646355011
2023-05-07 16:25:14,832:INFO: Early Stop Left: 6
2023-05-07 16:25:19,378:INFO: Epoch: 49 - loss: 0.0061668048 - test_loss: 0.1672858058
2023-05-07 16:25:19,378:INFO: Early Stop Left: 5
2023-05-07 16:25:23,926:INFO: Epoch: 50 - loss: 0.0060663758 - test_loss: 0.1656069868
2023-05-07 16:25:23,927:INFO: Early Stop Left: 4
