2023-05-07 16:01:33,510:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:01:33,512:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        4,280
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 6,784
Trainable params: 6,784
Non-trainable params: 0
===========================================================================
2023-05-07 16:02:49,767:INFO: -------------Data Proccessed------------
2023-05-07 16:02:49,808:INFO: -------------Teacher Model Loaded------------
2023-05-07 16:02:52,533:INFO: Epoch: 1 - loss: 0.2905467420 - test_loss: 0.6222797501
2023-05-07 16:02:52,535:INFO: -------- Save Best Model! --------
2023-05-07 16:02:54,828:INFO: Epoch: 2 - loss: 0.2385429191 - test_loss: 0.5355699426
2023-05-07 16:02:54,830:INFO: -------- Save Best Model! --------
2023-05-07 16:02:57,169:INFO: Epoch: 3 - loss: 0.1990942355 - test_loss: 0.4633648941
2023-05-07 16:02:57,170:INFO: -------- Save Best Model! --------
2023-05-07 16:02:59,544:INFO: Epoch: 4 - loss: 0.1654914727 - test_loss: 0.4021429907
2023-05-07 16:02:59,546:INFO: -------- Save Best Model! --------
2023-05-07 16:03:01,914:INFO: Epoch: 5 - loss: 0.1371887314 - test_loss: 0.3516448017
2023-05-07 16:03:01,916:INFO: -------- Save Best Model! --------
2023-05-07 16:03:04,234:INFO: Epoch: 6 - loss: 0.1139921367 - test_loss: 0.3111224923
2023-05-07 16:03:04,236:INFO: -------- Save Best Model! --------
2023-05-07 16:03:06,561:INFO: Epoch: 7 - loss: 0.0953920354 - test_loss: 0.2791788444
2023-05-07 16:03:06,563:INFO: -------- Save Best Model! --------
2023-05-07 16:03:08,873:INFO: Epoch: 8 - loss: 0.0806991929 - test_loss: 0.2544458210
2023-05-07 16:03:08,875:INFO: -------- Save Best Model! --------
2023-05-07 16:03:11,204:INFO: Epoch: 9 - loss: 0.0691921274 - test_loss: 0.2354693704
2023-05-07 16:03:11,206:INFO: -------- Save Best Model! --------
2023-05-07 16:03:13,520:INFO: Epoch: 10 - loss: 0.0602339952 - test_loss: 0.2209130776
2023-05-07 16:03:13,522:INFO: -------- Save Best Model! --------
2023-05-07 16:03:15,914:INFO: Epoch: 11 - loss: 0.0532144444 - test_loss: 0.2097287124
2023-05-07 16:03:15,915:INFO: -------- Save Best Model! --------
2023-05-07 16:03:18,243:INFO: Epoch: 12 - loss: 0.0476961618 - test_loss: 0.2012582087
2023-05-07 16:03:18,244:INFO: -------- Save Best Model! --------
2023-05-07 16:03:20,552:INFO: Epoch: 13 - loss: 0.0433103082 - test_loss: 0.1947348496
2023-05-07 16:03:20,554:INFO: -------- Save Best Model! --------
2023-05-07 16:03:22,853:INFO: Epoch: 14 - loss: 0.0397631454 - test_loss: 0.1896179362
2023-05-07 16:03:22,854:INFO: -------- Save Best Model! --------
2023-05-07 16:03:25,194:INFO: Epoch: 15 - loss: 0.0368133722 - test_loss: 0.1857154862
2023-05-07 16:03:25,195:INFO: -------- Save Best Model! --------
2023-05-07 16:03:27,521:INFO: Epoch: 16 - loss: 0.0342209445 - test_loss: 0.1832528214
2023-05-07 16:03:27,522:INFO: -------- Save Best Model! --------
2023-05-07 16:03:29,836:INFO: Epoch: 17 - loss: 0.0319104515 - test_loss: 0.1811682137
2023-05-07 16:03:29,838:INFO: -------- Save Best Model! --------
2023-05-07 16:03:32,171:INFO: Epoch: 18 - loss: 0.0297110309 - test_loss: 0.1794377158
2023-05-07 16:03:32,173:INFO: -------- Save Best Model! --------
2023-05-07 16:03:34,534:INFO: Epoch: 19 - loss: 0.0275985771 - test_loss: 0.1814107235
2023-05-07 16:03:34,534:INFO: Early Stop Left: 9
2023-05-07 16:03:36,965:INFO: Epoch: 20 - loss: 0.0254468645 - test_loss: 0.1778042413
2023-05-07 16:03:36,966:INFO: -------- Save Best Model! --------
2023-05-07 16:03:39,386:INFO: Epoch: 21 - loss: 0.0234143449 - test_loss: 0.1771203730
2023-05-07 16:03:39,387:INFO: -------- Save Best Model! --------
2023-05-07 16:03:41,784:INFO: Epoch: 22 - loss: 0.0215847677 - test_loss: 0.1760073195
2023-05-07 16:03:41,785:INFO: -------- Save Best Model! --------
2023-05-07 16:03:44,155:INFO: Epoch: 23 - loss: 0.0199790941 - test_loss: 0.1748415550
2023-05-07 16:03:44,156:INFO: -------- Save Best Model! --------
2023-05-07 16:03:46,548:INFO: Epoch: 24 - loss: 0.0184987524 - test_loss: 0.1725940021
2023-05-07 16:03:46,550:INFO: -------- Save Best Model! --------
2023-05-07 16:03:48,889:INFO: Epoch: 25 - loss: 0.0171653347 - test_loss: 0.1770423473
2023-05-07 16:03:48,889:INFO: Early Stop Left: 9
2023-05-07 16:03:51,226:INFO: Epoch: 26 - loss: 0.0162066901 - test_loss: 0.1743065809
2023-05-07 16:03:51,226:INFO: Early Stop Left: 8
2023-05-07 16:03:53,567:INFO: Epoch: 27 - loss: 0.0153083262 - test_loss: 0.1711725460
2023-05-07 16:03:53,568:INFO: -------- Save Best Model! --------
2023-05-07 16:03:55,972:INFO: Epoch: 28 - loss: 0.0144722626 - test_loss: 0.1724917638
2023-05-07 16:03:55,972:INFO: Early Stop Left: 9
2023-05-07 16:03:58,419:INFO: Epoch: 29 - loss: 0.0138647572 - test_loss: 0.1725913650
2023-05-07 16:03:58,419:INFO: Early Stop Left: 8
2023-05-07 16:04:00,812:INFO: Epoch: 30 - loss: 0.0132159623 - test_loss: 0.1719124110
2023-05-07 16:04:00,812:INFO: Early Stop Left: 7
2023-05-07 16:04:03,215:INFO: Epoch: 31 - loss: 0.0126687512 - test_loss: 0.1717279190
2023-05-07 16:04:03,215:INFO: Early Stop Left: 6
2023-05-07 16:04:05,645:INFO: Epoch: 32 - loss: 0.0120931775 - test_loss: 0.1695251256
2023-05-07 16:04:05,646:INFO: -------- Save Best Model! --------
2023-05-07 16:04:08,004:INFO: Epoch: 33 - loss: 0.0118548826 - test_loss: 0.1684197038
2023-05-07 16:04:08,005:INFO: -------- Save Best Model! --------
2023-05-07 16:04:10,367:INFO: Epoch: 34 - loss: 0.0112290043 - test_loss: 0.1705989374
2023-05-07 16:04:10,368:INFO: Early Stop Left: 9
2023-05-07 16:04:12,707:INFO: Epoch: 35 - loss: 0.0108439917 - test_loss: 0.1702689001
2023-05-07 16:04:12,707:INFO: Early Stop Left: 8
2023-05-07 16:04:15,046:INFO: Epoch: 36 - loss: 0.0104925353 - test_loss: 0.1698315623
2023-05-07 16:04:15,046:INFO: Early Stop Left: 7
2023-05-07 16:04:17,409:INFO: Epoch: 37 - loss: 0.0101633889 - test_loss: 0.1704735376
2023-05-07 16:04:17,409:INFO: Early Stop Left: 6
2023-05-07 16:04:19,749:INFO: Epoch: 38 - loss: 0.0098711811 - test_loss: 0.1702200669
2023-05-07 16:04:19,749:INFO: Early Stop Left: 5
2023-05-07 16:04:22,079:INFO: Epoch: 39 - loss: 0.0095759702 - test_loss: 0.1684196132
2023-05-07 16:04:22,081:INFO: -------- Save Best Model! --------
2023-05-07 16:04:24,414:INFO: Epoch: 40 - loss: 0.0092894371 - test_loss: 0.1695021275
2023-05-07 16:04:24,414:INFO: Early Stop Left: 9
2023-05-07 16:04:26,740:INFO: Epoch: 41 - loss: 0.0090101215 - test_loss: 0.1729483181
2023-05-07 16:04:26,740:INFO: Early Stop Left: 8
2023-05-07 16:04:29,146:INFO: Epoch: 42 - loss: 0.0088802122 - test_loss: 0.1715495728
2023-05-07 16:04:29,146:INFO: Early Stop Left: 7
2023-05-07 16:04:31,488:INFO: Epoch: 43 - loss: 0.0085748637 - test_loss: 0.1676518203
2023-05-07 16:04:31,490:INFO: -------- Save Best Model! --------
2023-05-07 16:04:33,850:INFO: Epoch: 44 - loss: 0.0083089121 - test_loss: 0.1657203877
2023-05-07 16:04:33,851:INFO: -------- Save Best Model! --------
2023-05-07 16:04:36,271:INFO: Epoch: 45 - loss: 0.0080955380 - test_loss: 0.1668555177
2023-05-07 16:04:36,271:INFO: Early Stop Left: 9
2023-05-07 16:04:38,671:INFO: Epoch: 46 - loss: 0.0079289451 - test_loss: 0.1696761549
2023-05-07 16:04:38,671:INFO: Early Stop Left: 8
2023-05-07 16:04:41,066:INFO: Epoch: 47 - loss: 0.0077128484 - test_loss: 0.1694332147
2023-05-07 16:04:41,066:INFO: Early Stop Left: 7
2023-05-07 16:04:43,445:INFO: Epoch: 48 - loss: 0.0074911487 - test_loss: 0.1660539766
2023-05-07 16:04:43,445:INFO: Early Stop Left: 6
2023-05-07 16:04:45,795:INFO: Epoch: 49 - loss: 0.0073447761 - test_loss: 0.1701416637
2023-05-07 16:04:45,795:INFO: Early Stop Left: 5
2023-05-07 16:04:48,122:INFO: Epoch: 50 - loss: 0.0070655799 - test_loss: 0.1645790388
2023-05-07 16:04:48,123:INFO: -------- Save Best Model! --------
2023-05-07 16:05:29,887:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:05:29,889:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        4,280
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 6,784
Trainable params: 6,784
Non-trainable params: 0
===========================================================================
2023-05-07 16:13:57,327:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:13:57,330:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               96
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 88
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        696
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              16
│    └─Linear: 2-5                                 2,304
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 3,200
Trainable params: 3,200
Non-trainable params: 0
===========================================================================
2023-05-07 16:20:20,915:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 16:20:20,918:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
│    │    └─ModuleList: 3-2                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 10,096
Trainable params: 10,096
Non-trainable params: 0
===========================================================================
2023-05-07 16:21:35,032:INFO: -------------Data Proccessed------------
2023-05-07 16:21:35,102:INFO: -------------Teacher Model Loaded------------
2023-05-07 16:21:40,002:INFO: Epoch: 1 - loss: 0.2663883834 - test_loss: 0.5463495066
2023-05-07 16:21:40,005:INFO: -------- Save Best Model! --------
2023-05-07 16:21:44,547:INFO: Epoch: 2 - loss: 0.1913581488 - test_loss: 0.4221579709
2023-05-07 16:21:44,549:INFO: -------- Save Best Model! --------
2023-05-07 16:21:49,098:INFO: Epoch: 3 - loss: 0.1387538081 - test_loss: 0.3376870061
2023-05-07 16:21:49,100:INFO: -------- Save Best Model! --------
2023-05-07 16:21:53,646:INFO: Epoch: 4 - loss: 0.1028946513 - test_loss: 0.2811196995
2023-05-07 16:21:53,649:INFO: -------- Save Best Model! --------
2023-05-07 16:21:58,197:INFO: Epoch: 5 - loss: 0.0786042678 - test_loss: 0.2435955990
2023-05-07 16:21:58,199:INFO: -------- Save Best Model! --------
2023-05-07 16:22:02,751:INFO: Epoch: 6 - loss: 0.0622760493 - test_loss: 0.2191970403
2023-05-07 16:22:02,753:INFO: -------- Save Best Model! --------
2023-05-07 16:22:07,305:INFO: Epoch: 7 - loss: 0.0513464503 - test_loss: 0.2032502897
2023-05-07 16:22:07,307:INFO: -------- Save Best Model! --------
2023-05-07 16:22:11,849:INFO: Epoch: 8 - loss: 0.0440037382 - test_loss: 0.1930403273
2023-05-07 16:22:11,851:INFO: -------- Save Best Model! --------
2023-05-07 16:22:16,393:INFO: Epoch: 9 - loss: 0.0390048816 - test_loss: 0.1865377041
2023-05-07 16:22:16,395:INFO: -------- Save Best Model! --------
2023-05-07 16:22:20,953:INFO: Epoch: 10 - loss: 0.0355854640 - test_loss: 0.1821166310
2023-05-07 16:22:20,955:INFO: -------- Save Best Model! --------
2023-05-07 16:22:25,519:INFO: Epoch: 11 - loss: 0.0331579787 - test_loss: 0.1792888403
2023-05-07 16:22:25,522:INFO: -------- Save Best Model! --------
2023-05-07 16:22:30,082:INFO: Epoch: 12 - loss: 0.0314152603 - test_loss: 0.1774316704
2023-05-07 16:22:30,084:INFO: -------- Save Best Model! --------
2023-05-07 16:22:34,640:INFO: Epoch: 13 - loss: 0.0301229509 - test_loss: 0.1762440566
2023-05-07 16:22:34,642:INFO: -------- Save Best Model! --------
2023-05-07 16:22:39,195:INFO: Epoch: 14 - loss: 0.0289987211 - test_loss: 0.1747859062
2023-05-07 16:22:39,197:INFO: -------- Save Best Model! --------
2023-05-07 16:22:43,750:INFO: Epoch: 15 - loss: 0.0274482871 - test_loss: 0.1735962913
2023-05-07 16:22:43,752:INFO: -------- Save Best Model! --------
2023-05-07 16:22:48,311:INFO: Epoch: 16 - loss: 0.0254644725 - test_loss: 0.1733010987
2023-05-07 16:22:48,313:INFO: -------- Save Best Model! --------
2023-05-07 16:22:52,865:INFO: Epoch: 17 - loss: 0.0233822696 - test_loss: 0.1729735767
2023-05-07 16:22:52,867:INFO: -------- Save Best Model! --------
2023-05-07 16:22:57,428:INFO: Epoch: 18 - loss: 0.0212476257 - test_loss: 0.1728900402
2023-05-07 16:22:57,430:INFO: -------- Save Best Model! --------
2023-05-07 16:23:01,980:INFO: Epoch: 19 - loss: 0.0190659480 - test_loss: 0.1722366348
2023-05-07 16:23:01,982:INFO: -------- Save Best Model! --------
2023-05-07 16:23:06,548:INFO: Epoch: 20 - loss: 0.0173396068 - test_loss: 0.1796032674
2023-05-07 16:23:06,548:INFO: Early Stop Left: 9
2023-05-07 16:23:11,115:INFO: Epoch: 21 - loss: 0.0158420172 - test_loss: 0.1829371340
2023-05-07 16:23:11,115:INFO: Early Stop Left: 8
2023-05-07 16:23:15,666:INFO: Epoch: 22 - loss: 0.0148227705 - test_loss: 0.1759463131
2023-05-07 16:23:15,666:INFO: Early Stop Left: 7
2023-05-07 16:23:20,213:INFO: Epoch: 23 - loss: 0.0139506787 - test_loss: 0.1756081746
2023-05-07 16:23:20,213:INFO: Early Stop Left: 6
2023-05-07 16:23:24,758:INFO: Epoch: 24 - loss: 0.0132194751 - test_loss: 0.1698821134
2023-05-07 16:23:24,760:INFO: -------- Save Best Model! --------
2023-05-07 16:23:29,313:INFO: Epoch: 25 - loss: 0.0125071645 - test_loss: 0.1724421306
2023-05-07 16:23:29,313:INFO: Early Stop Left: 9
2023-05-07 16:23:33,883:INFO: Epoch: 26 - loss: 0.0117934265 - test_loss: 0.1745368059
2023-05-07 16:23:33,883:INFO: Early Stop Left: 8
2023-05-07 16:23:38,446:INFO: Epoch: 27 - loss: 0.0114728876 - test_loss: 0.1808718230
2023-05-07 16:23:38,446:INFO: Early Stop Left: 7
2023-05-07 16:23:43,014:INFO: Epoch: 28 - loss: 0.0108484131 - test_loss: 0.1719297514
2023-05-07 16:23:43,014:INFO: Early Stop Left: 6
2023-05-07 16:23:47,597:INFO: Epoch: 29 - loss: 0.0103790961 - test_loss: 0.1697127943
2023-05-07 16:23:47,598:INFO: -------- Save Best Model! --------
2023-05-07 16:23:52,162:INFO: Epoch: 30 - loss: 0.0099874101 - test_loss: 0.1735632512
2023-05-07 16:23:52,163:INFO: Early Stop Left: 9
2023-05-07 16:23:56,726:INFO: Epoch: 31 - loss: 0.0095694882 - test_loss: 0.1703087973
2023-05-07 16:23:56,726:INFO: Early Stop Left: 8
2023-05-07 16:24:01,314:INFO: Epoch: 32 - loss: 0.0091959015 - test_loss: 0.1653150015
2023-05-07 16:24:01,316:INFO: -------- Save Best Model! --------
2023-05-07 16:24:05,912:INFO: Epoch: 33 - loss: 0.0089608561 - test_loss: 0.1683705547
2023-05-07 16:24:05,913:INFO: Early Stop Left: 9
2023-05-07 16:24:10,498:INFO: Epoch: 34 - loss: 0.0086088271 - test_loss: 0.1714338700
2023-05-07 16:24:10,499:INFO: Early Stop Left: 8
2023-05-07 16:24:15,105:INFO: Epoch: 35 - loss: 0.0084471784 - test_loss: 0.1699361534
2023-05-07 16:24:15,105:INFO: Early Stop Left: 7
2023-05-07 16:24:19,685:INFO: Epoch: 36 - loss: 0.0082173748 - test_loss: 0.1734184270
2023-05-07 16:24:19,685:INFO: Early Stop Left: 6
2023-05-07 16:24:24,269:INFO: Epoch: 37 - loss: 0.0079381970 - test_loss: 0.1694226954
2023-05-07 16:24:24,269:INFO: Early Stop Left: 5
2023-05-07 16:24:28,872:INFO: Epoch: 38 - loss: 0.0078114082 - test_loss: 0.1699265009
2023-05-07 16:24:28,872:INFO: Early Stop Left: 4
2023-05-07 16:24:33,444:INFO: Epoch: 39 - loss: 0.0077106284 - test_loss: 0.1678854692
2023-05-07 16:24:33,444:INFO: Early Stop Left: 3
2023-05-07 16:24:38,033:INFO: Epoch: 40 - loss: 0.0076130887 - test_loss: 0.1707128722
2023-05-07 16:24:38,034:INFO: Early Stop Left: 2
2023-05-07 16:24:42,656:INFO: Epoch: 41 - loss: 0.0074062905 - test_loss: 0.1680392994
2023-05-07 16:24:42,656:INFO: Early Stop Left: 1
2023-05-07 16:24:47,266:INFO: Epoch: 42 - loss: 0.0072762732 - test_loss: 0.1650894450
2023-05-07 16:24:47,268:INFO: -------- Save Best Model! --------
2023-05-07 16:24:51,896:INFO: Epoch: 43 - loss: 0.0069964966 - test_loss: 0.1670668398
2023-05-07 16:24:51,896:INFO: Early Stop Left: 9
2023-05-07 16:24:56,501:INFO: Epoch: 44 - loss: 0.0068722494 - test_loss: 0.1635670440
2023-05-07 16:24:56,503:INFO: -------- Save Best Model! --------
2023-05-07 16:25:01,145:INFO: Epoch: 45 - loss: 0.0067407191 - test_loss: 0.1671936156
2023-05-07 16:25:01,146:INFO: Early Stop Left: 9
2023-05-07 16:25:05,735:INFO: Epoch: 46 - loss: 0.0066236227 - test_loss: 0.1661677648
2023-05-07 16:25:05,735:INFO: Early Stop Left: 8
2023-05-07 16:25:10,288:INFO: Epoch: 47 - loss: 0.0065120317 - test_loss: 0.1646148254
2023-05-07 16:25:10,289:INFO: Early Stop Left: 7
2023-05-07 16:25:14,832:INFO: Epoch: 48 - loss: 0.0064092986 - test_loss: 0.1646355011
2023-05-07 16:25:14,832:INFO: Early Stop Left: 6
2023-05-07 16:25:19,378:INFO: Epoch: 49 - loss: 0.0061668048 - test_loss: 0.1672858058
2023-05-07 16:25:19,378:INFO: Early Stop Left: 5
2023-05-07 16:25:23,926:INFO: Epoch: 50 - loss: 0.0060663758 - test_loss: 0.1656069868
2023-05-07 16:25:23,927:INFO: Early Stop Left: 4
2023-05-07 17:21:21,725:INFO: /home/neel/Desktop/LoadTraces/spec06/473.astar-s0.txt.xz
2023-05-07 17:21:21,728:INFO: ===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
│    │    └─ModuleList: 3-2                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
├─Sigmoid: 1-6                                     --
===========================================================================
Total params: 10,096
Trainable params: 10,096
Non-trainable params: 0
===========================================================================
2023-05-07 17:22:35,006:INFO: -------------Data Proccessed------------
2023-05-07 17:22:35,066:INFO: -------------Teacher Model Loaded------------
2023-05-07 17:22:39,934:INFO: Epoch: 1 - loss: 0.2822640742 - test_loss: 0.5540626064
2023-05-07 17:22:39,936:INFO: -------- Save Best Model! --------
2023-05-07 17:22:44,453:INFO: Epoch: 2 - loss: 0.1980992832 - test_loss: 0.4320816965
2023-05-07 17:22:44,455:INFO: -------- Save Best Model! --------
2023-05-07 17:22:48,984:INFO: Epoch: 3 - loss: 0.1471842800 - test_loss: 0.3485856151
2023-05-07 17:22:48,986:INFO: -------- Save Best Model! --------
2023-05-07 17:22:53,515:INFO: Epoch: 4 - loss: 0.1111210336 - test_loss: 0.2901717272
2023-05-07 17:22:53,517:INFO: -------- Save Best Model! --------
2023-05-07 17:22:58,044:INFO: Epoch: 5 - loss: 0.0858713906 - test_loss: 0.2504489607
2023-05-07 17:22:58,046:INFO: -------- Save Best Model! --------
2023-05-07 17:23:02,579:INFO: Epoch: 6 - loss: 0.0685962232 - test_loss: 0.2241888730
2023-05-07 17:23:02,581:INFO: -------- Save Best Model! --------
2023-05-07 17:23:07,108:INFO: Epoch: 7 - loss: 0.0568901889 - test_loss: 0.2068065071
2023-05-07 17:23:07,110:INFO: -------- Save Best Model! --------
2023-05-07 17:23:11,606:INFO: Epoch: 8 - loss: 0.0489418133 - test_loss: 0.1954955291
2023-05-07 17:23:11,608:INFO: -------- Save Best Model! --------
2023-05-07 17:23:16,124:INFO: Epoch: 9 - loss: 0.0434842660 - test_loss: 0.1881847923
2023-05-07 17:23:16,126:INFO: -------- Save Best Model! --------
2023-05-07 17:23:20,650:INFO: Epoch: 10 - loss: 0.0397135011 - test_loss: 0.1831791933
2023-05-07 17:23:20,652:INFO: -------- Save Best Model! --------
2023-05-07 17:23:25,182:INFO: Epoch: 11 - loss: 0.0370226083 - test_loss: 0.1798870451
2023-05-07 17:23:25,184:INFO: -------- Save Best Model! --------
2023-05-07 17:23:29,729:INFO: Epoch: 12 - loss: 0.0350826387 - test_loss: 0.1777408443
2023-05-07 17:23:29,731:INFO: -------- Save Best Model! --------
2023-05-07 17:23:34,274:INFO: Epoch: 13 - loss: 0.0336273884 - test_loss: 0.1763717107
2023-05-07 17:23:34,276:INFO: -------- Save Best Model! --------
2023-05-07 17:23:38,821:INFO: Epoch: 14 - loss: 0.0321944804 - test_loss: 0.1745561974
2023-05-07 17:23:38,823:INFO: -------- Save Best Model! --------
2023-05-07 17:23:43,369:INFO: Epoch: 15 - loss: 0.0300647968 - test_loss: 0.1738152240
2023-05-07 17:23:43,371:INFO: -------- Save Best Model! --------
2023-05-07 17:23:47,981:INFO: Epoch: 16 - loss: 0.0276078797 - test_loss: 0.1737201712
2023-05-07 17:23:47,982:INFO: -------- Save Best Model! --------
2023-05-07 17:23:52,581:INFO: Epoch: 17 - loss: 0.0250131172 - test_loss: 0.1713029502
2023-05-07 17:23:52,582:INFO: -------- Save Best Model! --------
2023-05-07 17:23:57,267:INFO: Epoch: 18 - loss: 0.0219168475 - test_loss: 0.1744930864
2023-05-07 17:23:57,267:INFO: Early Stop Left: 9
2023-05-07 17:24:01,822:INFO: Epoch: 19 - loss: 0.0194101012 - test_loss: 0.1751916845
2023-05-07 17:24:01,822:INFO: Early Stop Left: 8
2023-05-07 17:24:06,377:INFO: Epoch: 20 - loss: 0.0175955535 - test_loss: 0.1696438195
2023-05-07 17:24:06,379:INFO: -------- Save Best Model! --------
2023-05-07 17:24:10,949:INFO: Epoch: 21 - loss: 0.0161971116 - test_loss: 0.1737771507
2023-05-07 17:24:10,949:INFO: Early Stop Left: 9
2023-05-07 17:24:15,518:INFO: Epoch: 22 - loss: 0.0150460848 - test_loss: 0.1676982281
2023-05-07 17:24:15,520:INFO: -------- Save Best Model! --------
2023-05-07 17:24:20,084:INFO: Epoch: 23 - loss: 0.0140047856 - test_loss: 0.1630774564
2023-05-07 17:24:20,086:INFO: -------- Save Best Model! --------
2023-05-07 17:24:24,663:INFO: Epoch: 24 - loss: 0.0131497713 - test_loss: 0.1593635669
2023-05-07 17:24:24,665:INFO: -------- Save Best Model! --------
2023-05-07 17:24:29,253:INFO: Epoch: 25 - loss: 0.0123976055 - test_loss: 0.1624894720
2023-05-07 17:24:29,253:INFO: Early Stop Left: 9
2023-05-07 17:24:33,834:INFO: Epoch: 26 - loss: 0.0115977163 - test_loss: 0.1634059392
2023-05-07 17:24:33,834:INFO: Early Stop Left: 8
2023-05-07 17:24:38,410:INFO: Epoch: 27 - loss: 0.0108648404 - test_loss: 0.1637431410
2023-05-07 17:24:38,410:INFO: Early Stop Left: 7
2023-05-07 17:24:42,968:INFO: Epoch: 28 - loss: 0.0101295966 - test_loss: 0.1597201357
2023-05-07 17:24:42,968:INFO: Early Stop Left: 6
2023-05-07 17:24:47,527:INFO: Epoch: 29 - loss: 0.0093660825 - test_loss: 0.1598200218
2023-05-07 17:24:47,527:INFO: Early Stop Left: 5
2023-05-07 17:24:52,084:INFO: Epoch: 30 - loss: 0.0088510709 - test_loss: 0.1580754500
2023-05-07 17:24:52,086:INFO: -------- Save Best Model! --------
2023-05-07 17:24:56,657:INFO: Epoch: 31 - loss: 0.0082720919 - test_loss: 0.1574409464
2023-05-07 17:24:56,659:INFO: -------- Save Best Model! --------
2023-05-07 17:25:01,228:INFO: Epoch: 32 - loss: 0.0079534957 - test_loss: 0.1576320569
2023-05-07 17:25:01,228:INFO: Early Stop Left: 9
2023-05-07 17:25:05,789:INFO: Epoch: 33 - loss: 0.0075531970 - test_loss: 0.1610112470
2023-05-07 17:25:05,789:INFO: Early Stop Left: 8
2023-05-07 17:25:10,360:INFO: Epoch: 34 - loss: 0.0071410419 - test_loss: 0.1607589195
2023-05-07 17:25:10,361:INFO: Early Stop Left: 7
2023-05-07 17:25:14,926:INFO: Epoch: 35 - loss: 0.0070032493 - test_loss: 0.1596156382
2023-05-07 17:25:14,926:INFO: Early Stop Left: 6
2023-05-07 17:25:19,491:INFO: Epoch: 36 - loss: 0.0066811065 - test_loss: 0.1594631470
2023-05-07 17:25:19,491:INFO: Early Stop Left: 5
2023-05-07 17:25:24,064:INFO: Epoch: 37 - loss: 0.0064323421 - test_loss: 0.1563345621
2023-05-07 17:25:24,066:INFO: -------- Save Best Model! --------
2023-05-07 17:25:28,638:INFO: Epoch: 38 - loss: 0.0063402866 - test_loss: 0.1594221928
2023-05-07 17:25:28,638:INFO: Early Stop Left: 9
2023-05-07 17:25:33,212:INFO: Epoch: 39 - loss: 0.0061505738 - test_loss: 0.1575178417
2023-05-07 17:25:33,213:INFO: Early Stop Left: 8
2023-05-07 17:25:37,792:INFO: Epoch: 40 - loss: 0.0059079959 - test_loss: 0.1561576851
2023-05-07 17:25:37,794:INFO: -------- Save Best Model! --------
2023-05-07 17:25:42,384:INFO: Epoch: 41 - loss: 0.0057783994 - test_loss: 0.1558851452
2023-05-07 17:25:42,386:INFO: -------- Save Best Model! --------
2023-05-07 17:25:46,976:INFO: Epoch: 42 - loss: 0.0056770420 - test_loss: 0.1549008787
2023-05-07 17:25:46,978:INFO: -------- Save Best Model! --------
2023-05-07 17:25:51,571:INFO: Epoch: 43 - loss: 0.0055809385 - test_loss: 0.1554191053
2023-05-07 17:25:51,571:INFO: Early Stop Left: 9
2023-05-07 17:25:56,157:INFO: Epoch: 44 - loss: 0.0054530129 - test_loss: 0.1541939323
2023-05-07 17:25:56,158:INFO: -------- Save Best Model! --------
2023-05-07 17:26:00,748:INFO: Epoch: 45 - loss: 0.0055180865 - test_loss: 0.1568915182
2023-05-07 17:26:00,748:INFO: Early Stop Left: 9
2023-05-07 17:26:05,337:INFO: Epoch: 46 - loss: 0.0052095873 - test_loss: 0.1582649897
2023-05-07 17:26:05,337:INFO: Early Stop Left: 8
2023-05-07 17:26:09,931:INFO: Epoch: 47 - loss: 0.0052106557 - test_loss: 0.1555972601
2023-05-07 17:26:09,931:INFO: Early Stop Left: 7
2023-05-07 17:26:14,522:INFO: Epoch: 48 - loss: 0.0050378399 - test_loss: 0.1570815322
2023-05-07 17:26:14,522:INFO: Early Stop Left: 6
2023-05-07 17:26:19,109:INFO: Epoch: 49 - loss: 0.0050354919 - test_loss: 0.1550588421
2023-05-07 17:26:19,109:INFO: Early Stop Left: 5
2023-05-07 17:26:23,694:INFO: Epoch: 50 - loss: 0.0049848695 - test_loss: 0.1587088680
2023-05-07 17:26:23,694:INFO: Early Stop Left: 4
